#!/usr/bin/env python3
"""
Debug LLM invocation
"""

import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

def debug_llm():
    """Debug LLM invocation"""
    print("ğŸ§ª Debugging LLM Invocation")
    print("=" * 30)
    
    try:
        from langgraph_chatbot import get_chatbot
        
        print("âœ… Successfully imported langgraph_chatbot")
        
        # Get chatbot instance
        chatbot = get_chatbot()
        print("âœ… Successfully created chatbot instance")
        
        # Test query
        query = "What are typical lease terms in Texas?"
        print(f"ğŸ” Testing query: {query}")
        
        # Create initial state
        initial_state = {
            "query": query,
            "conversation_history": [],
            "needs_web_search": False,
            "web_search_results": ""
        }
        
        print("ğŸ“Š Running LangGraph...")
        
        # Run the graph
        result = chatbot.graph.invoke(initial_state)
        
        print("âœ… LangGraph completed!")
        
        # Get the streaming messages
        messages = result.get("streaming_messages", [])
        
        if not messages:
            print("âŒ No streaming messages found!")
            return
        
        print(f"âœ… Found {len(messages)} streaming messages")
        
        # Test LLM invocation
        print("ğŸ¤– Testing LLM invocation...")
        
        try:
            response = chatbot.llm.invoke(messages)
            print(f"âœ… LLM response type: {type(response)}")
            print(f"ğŸ“ LLM response: {response}")
            
            if hasattr(response, 'content'):
                print(f"ğŸ“ Response content: '{response.content}'")
            else:
                print(f"ğŸ“ Response string: '{str(response)}'")
                
        except Exception as e:
            print(f"âŒ LLM error: {e}")
            import traceback
            traceback.print_exc()
            
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_llm()
